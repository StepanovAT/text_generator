{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394a5f52-ab35-4ef3-8c9d-5f0aa42a438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a105ce11-6a87-498b-a6b5-39ef921039fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oбщaя длина: 98328\n",
      "Уникальных символов: 92\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "## Чтение и nредварительная обработка текста \n",
    "text = ' '.join(list(df['response']))\n",
    "start_indx = text.find('Шла вчера я по Садовой')\n",
    "end_indx = text.find('Я, как мама, не люблю')\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print(\"Oбщaя длина:\", len(text))\n",
    "print(\"Уникальных символов:\", len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e06a36c-d81b-429f-adf1-0222327ea78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paзмep закодированного текста:  (98328,)\n",
      "Шла вчера я по Сад      == Кодирование ==>  [49 66 55  1 57 78 60 71 55  1 86  1 70 69  1]\n",
      "[57 69 64  6  0 43 55 65  1 56 82 66 55  1 74 59 63 57 66 60 68 55]  == Декодирование  ==>  вой,\n",
      "Так была удивлена\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "\n",
    "print('Paзмep закодированного текста: ', text_encoded.shape)\n",
    "\n",
    "print(text[:18], '     == Кодирование ==> ', text_encoded[:15])\n",
    "print(text_encoded[19:41], ' == Декодирование  ==> ', ''.join(char_array[text_encoded[19:41]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b09c305-2d55-4ac8-bab1-5367cb78a55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 -> Ш\n",
      "66 -> л\n",
      "55 -> а\n",
      "1 ->  \n",
      "57 -> в\n",
      "78 -> ч\n",
      "60 -> е\n",
      "71 -> р\n",
      "55 -> а\n",
      "1 ->  \n",
      "86 -> я\n",
      "1 ->  \n"
     ]
    }
   ],
   "source": [
    "for ex in text_encoded[:12]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc13dc1-c15b-4fba-8775-a44f4875ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 66 55  1 57 78 60 71 55  1 86  1 70 69  1 42 55 59 69 57 69 64  6  0\n",
      " 43 55 65  1 56 82 66 55  1 74 59 63 57 66 60 68 55  1 89  0 40 55]  ->  71\n",
      "'Шла вчера я по Садовой,\\nТак была удивлена —\\nПа'  ->  'р'\n"
     ]
    }
   ],
   "source": [
    "seq_length = 46\n",
    "chunk_size = seq_length+1\n",
    "\n",
    "text_chunks = [text_encoded[i:i+chunk_size] \n",
    "               for i in range(len(text_encoded)-chunk_size+1)] \n",
    "\n",
    "## inspection:\n",
    "for seq in text_chunks[:1]:\n",
    "    input_seq = seq[:seq_length]\n",
    "    target = seq[seq_length] \n",
    "    print(input_seq, ' -> ', target)\n",
    "    print(repr(''.join(char_array[input_seq])), \n",
    "          ' -> ', repr(''.join(char_array[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe773bd-42d7-4052-a12f-66acfd870bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ainur\\AppData\\Local\\Temp\\ipykernel_12096\\2527503007.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "    \n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfddab3d-ddd8-4c95-b184-7b3d599b4cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вход (х): 'Шла вчера я по Садовой,\\nТак была удивлена —\\nПа'\n",
      "Цель (у): 'ла вчера я по Садовой,\\nТак была удивлена —\\nПар'\n",
      "\n",
      "Вход (х): 'ла вчера я по Садовой,\\nТак была удивлена —\\nПар'\n",
      "Цель (у): 'а вчера я по Садовой,\\nТак была удивлена —\\nПаре'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print('Вход (х):', repr(''.join(char_array[seq])))\n",
    "    print('Цель (у):', repr(''.join(char_array[target])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f872d8-f6cf-4ad3-a832-5d5d6edc1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    "batch_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0ac7a4-58f7-4ef3-afa1-65bdf31a109f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(92, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=92, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim) \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden.to(device), cell.to(device)\n",
    "    \n",
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size) \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e50bcf-9ad0-482e-8f89-531bea1cdde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0 loss: 4.5285\n",
      "Эпоха 500 loss: 1.2750\n",
      "Эпоха 1000 loss: 0.8007\n",
      "Эпоха 1500 loss: 0.6771\n",
      "Эпоха 2000 loss: 0.6386\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 2500\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell) \n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Эпоха {epoch} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e447b2ec-b8d2-4abd-b4ad-3eb0197d9106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятности: [0.33333334 0.33333334 0.33333334]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "logits = torch.tensor([[1.0, 1.0, 1.0]])\n",
    "\n",
    "print('Вероятности:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    " \n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb88dc54-e06b-4d6c-8642-e94e687f512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятности: [0.10650698 0.10650698 0.78698605]\n",
      "[[0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Вероятности:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    " \n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec039cd-f0c4-4d0a-974e-b03dc6152e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шла вчера я не терпит\n",
      "Чуждик Моют рожиц мне поражали!\n",
      "С аспаху так поражевает,\n",
      "Что волюке и мести очень улыбалась,\n",
      "Чтоб в жизни не гряют в дневнике.\n",
      "Он идем обливаться нету дождь\n",
      "Над землёз пронется в чистый листом.\n",
      "Что девочки и бородой,\n",
      "В переводче своет доме.\n",
      "\n",
      "От Андрюши:\n",
      "Моря до летает\n",
      "Догадаться,\n",
      "Что же дедушка Морозу нужны,\n",
      "Чтоб за то, что в школьной. Спит и ухал ростовый год! Есть в нарядные ение:\n",
      "«Краша А елки\n",
      "И однаждым огорченицо.\n",
      "\n",
      "Все мечты осуществи! — Ну, тяте осталась\n",
      "Приносита егоза сказка!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sample(model, starting_str, \n",
    "           len_generated_text=500, \n",
    "           scale_factor=1.0):\n",
    "\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    hidden = hidden.to('cpu')\n",
    "    cell = cell.to('cpu')\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell) \n",
    "    \n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(last_char.view(1), hidden, cell) \n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "        \n",
    "    return generated_str\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model.to('cpu')\n",
    "print(sample(model, starting_str='Шла вчера я'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1c627b-4a77-4ffc-bb19-500c3eb437d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятности до масштабирования: [0.10650698 0.10650698 0.78698605]\n",
      "Вероятности nосле масштабирования 0.5: [0.21194156 0.21194156 0.57611686]\n",
      "Вероятности после масштабирования 0.1: [0.3104238  0.3104238  0.37915248]\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Вероятности до масштабирования:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "print(\"Вероятности nосле масштабирования 0.5:\", nn.functional.softmax(0.5*logits, dim=1).numpy()[0])\n",
    "\n",
    "print('Вероятности после масштабирования 0.1:', nn.functional.softmax(0.1*logits, dim=1).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbaaaac2-b9df-4aa8-b647-d82accbbc6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "приветство здесь смеется...\n",
      "Рыпливо, Ты посмотрите, что спешим мы никакие отках,\n",
      "В белые сели\n",
      "По пояса, но полон!\n",
      "Мы решили не молчат с вами заплавать пора в эту дочки. Борода, самой малышок! Ах, как корабли;\n",
      "С клупки, поздравить мама:\n",
      "– В мир знание – сила,\n",
      "Во всегда мы много раз!\n",
      "Но такое хвостика красный\n",
      "Весёлым батарешку.\n",
      "Любим её полянку,\n",
      "А на уроках день-дарина,\n",
      "Но такое и ни слова нет, чем мой юрный крик. Любимое смоетые,\n",
      "Неважно, что растает.\n",
      "Но в книжку у он их не узнались.\n",
      "Слицы давай жить.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='привет'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c33d45fb-d04c-4975-9581-d2b3d392e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "привета нету смеету,\n",
      "И гориц Гармитикая, сплясался бор!\n",
      "Но невётя мороз...\n",
      "Вять лукворжевый! Рыжий?ка готовая.\n",
      "— Ну, капилась мила\n",
      "И совершиная\n",
      "Сыгию, рона, нал он кто-то стоит,\n",
      "Уставшие отличали:\n",
      "- Шитаем!\n",
      "В емУл Считомо,\n",
      "Это пабли я кзо притки! Ручко – кроЖе,\n",
      "Кругом стюнутый д\n",
      "Ир жел у Кол,\n",
      "А в боре снежной батаре.\n",
      "Говорит:— оам\n",
      "Матричница дюбочек.\n",
      "Отехлилица нечагают\n",
      "Буке мучи\n",
      "И настроется вам надудачки, Капачке.\n",
      "Но куда но пошёлте,\n",
      "Где на вруды лепит\n",
      "Долк\n",
      "Луются волхода?\n",
      "АМымите! \n",
      "Пусть немуров не\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='привет',scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cbe926d-87ba-4883-97da-da370f756b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Викала\n",
      "Скачу На пути\"?\n",
      "Прогресть нахмуров и ренок,\n",
      "Шерсть понимая мальчикку:\n",
      "Любит напери-кряем.\n",
      "Ведье жизнь, и кнов,\n",
      "Ты тольное. Днес — Уколку.\n",
      "Мы зажглась Зимой выша\n",
      "Этая и ороно.\n",
      "\n",
      "оучите Андрей: - Молоко, скорпевая\n",
      "Пестей барщиw нь… Я эти мила -\n",
      "От старим кто знаю.\n",
      "Апешье себя привечае,\n",
      "Когожка, Идет, ябребе белизнул,\n",
      "Погая тоша дар-цазлопать,\n",
      "Можно вам кудачной!—\n",
      "Рiитётся общевия,\n",
      "Прижное блеж…\n",
      "А я двигда жалежим...\n",
      "Эй, он держуз изблавы.\n",
      "Все балогами — с наши влезщещь:\n",
      "Могу, табаба я будет бязу\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='Вика',scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec032482-4a88-44aa-9c07-2f6dc944afcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
